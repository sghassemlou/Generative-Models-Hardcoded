# Generative Models-Hardcode

## Comparison of Generative Paradigms on CIFAR-10 **[Section 1](https://github.com/sghassemlou/Generative-Models-Hardcoded/tree/master/Section1)**
DCGAN, convolutional VAE, PixelCNN, and DDPM, trained the CIFAR-10 dataset

[See Notebook](https://github.com/sghassemlou/Generative-Models-Hardcoded/blob/master/Section1/Gen_Paradigms_Notebook.ipynb)

### Summary of Metrics for DCGAN, VAE, PixelXNN DDPM
[.json summary](https://github.com/sghassemlou/Generative-Models-Hardcoded/blob/master/Section1/artifacts/metrics_summary.json)

![](https://github.com/sghassemlou/Generative-Models-Hardcoded/blob/master/Section1/artifacts/metrics%20summary.png "")
### PixelCNN NLL Estimate During Training (Baseline)
![](https://github.com/sghassemlou/Generative-Models-Hardcoded/blob/master/Section1/artifacts/pixelcnn_nll_plot.png) "")
### VAE NLL Estimate During Training (Baseline)
![](https://github.com/sghassemlou/Generative-Models-Hardcoded/blob/master/Section1/artifacts/vae_nll_plot.png "")
### Aggregate Plots KID vs Inference Speed, Likelihood VS training Compute
![](https://github.com/sghassemlou/Generative-Models-Hardcoded/blob/master/Section1/artifacts/aggregate_plots.png "")

## Diffusion on MNIST: DDPM and Classifier-Free Guidance **[Section 2](https://github.com/sghassemlou/Generative-Models-Hardcoded/tree/master/Section1)**
Implementing and compare two diffusion-based generative models on the MNIST datase

[See Notebook](https://github.com/sghassemlou/Generative-Models-Hardcoded/blob/master/Section2/Diffusion_Notebook.ipynb)

[Output](https://github.com/sghassemlou/Generative-Models-Hardcoded/tree/master/Section2/results_diffusion)
